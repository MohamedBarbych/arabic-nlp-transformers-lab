{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbc46003",
   "metadata": {},
   "source": [
    "\n",
    "# 🧠 Deep Learning – Atelier 3 – Scraping & Sequence Models\n",
    "\n",
    "**Université Abdelmalek Essaadi – Master MBD**  \n",
    "**Instructor:** Pr. ELAACHAK LOTFI  \n",
    "**Lab 3 Objective:** Familiarization with PyTorch and building sequence models for Arabic NLP tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 Part 1: Classification Task (Text Collection & Preprocessing)\n",
    "\n",
    "### ✅ Step 1: Arabic News Scraping\n",
    "\n",
    "We will scrape Arabic political news titles from [Hespress Politics](https://www.hespress.com/politique) using **Selenium** with a headless Chrome driver and **BeautifulSoup**. We'll simulate infinite scrolling for 60 seconds and extract all headlines.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b1dda2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 📦 Install required packages\n",
    "!pip install selenium beautifulsoup4 pandas webdriver-manager\n",
    "\n",
    "# ✅ Import Libraries\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "# ✅ Headless Chrome Setup\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# ✅ URL of the page to scrape\n",
    "url = \"https://www.hespress.com/politique\"\n",
    "driver.get(url)\n",
    "\n",
    "# ✅ Scroll for 60 seconds to simulate infinite scroll\n",
    "start_time = time.time()\n",
    "SCROLL_PAUSE_TIME = 2\n",
    "\n",
    "while time.time() - start_time < 60:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "# ✅ Get page source and parse with BeautifulSoup\n",
    "soup = BeautifulSoup(driver.page_source, \"html.parser\")\n",
    "driver.quit()\n",
    "\n",
    "# ✅ Extract article titles\n",
    "titles = [a.get_text(strip=True) for a in soup.select(\"a.stretched-link\")]\n",
    "\n",
    "# ✅ Store in DataFrame\n",
    "df = pd.DataFrame({\"text\": titles})\n",
    "df[\"score\"] = 0  # Initialize score column\n",
    "\n",
    "# ✅ Save to CSV\n",
    "df.to_csv(\"news.csv\", index=False)\n",
    "\n",
    "# ✅ Preview\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d53d3ad",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ✍️ What's Next?\n",
    "\n",
    "- Continue with text preprocessing: tokenization, stemming, lemmatization, etc.\n",
    "- Train sequence models: RNN, Bi-RNN, GRU, and LSTM.\n",
    "- Evaluate models using metrics (Accuracy, BLEU Score, etc.)\n",
    "- Prepare the README and GitHub push.\n",
    "\n",
    "> ✅ This notebook is Colab-compatible and can be reused directly.\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
