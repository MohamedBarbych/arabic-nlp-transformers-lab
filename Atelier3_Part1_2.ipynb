{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcb98921-db40-4c14-bebe-8a277a3dd118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /home/med/jupyter_env/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: scikit-learn in /home/med/jupyter_env/lib/python3.12/site-packages (1.5.2)\n",
      "Requirement already satisfied: torch in /home/med/jupyter_env/lib/python3.12/site-packages (2.6.0+cu118)\n",
      "Requirement already satisfied: click in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /home/med/jupyter_env/lib/python3.12/site-packages (from scikit-learn) (2.1.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from scikit-learn) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: filelock in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.8.89 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.8.89 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.8.89)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.8.87 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.8.87)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==9.1.0.70 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (9.1.0.70)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.11.3.6 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.11.3.6)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.3.0.86 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (10.3.0.86)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.1.48 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.4.1.48)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.5.86 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.7.5.86)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.21.5 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (2.21.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.8.86 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (11.8.86)\n",
      "Requirement already satisfied: triton==3.2.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (3.2.0)\n",
      "Requirement already satisfied: setuptools in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (75.4.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /home/med/jupyter_env/lib/python3.12/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "===== RNN Evaluation =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/med/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.453416149068323\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.12      0.20        34\n",
      "           1       0.45      0.90      0.60        69\n",
      "           2       0.41      0.13      0.20        52\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.45       161\n",
      "   macro avg       0.38      0.29      0.25       161\n",
      "weighted avg       0.47      0.45      0.36       161\n",
      "\n",
      "===== BIRNN Evaluation =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.484472049689441\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.38      0.43        34\n",
      "           1       0.51      0.71      0.59        69\n",
      "           2       0.41      0.31      0.35        52\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.48       161\n",
      "   macro avg       0.36      0.35      0.34       161\n",
      "weighted avg       0.46      0.48      0.46       161\n",
      "\n",
      "===== GRU Evaluation =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        34\n",
      "           1       0.44      0.93      0.59        69\n",
      "           2       0.38      0.10      0.15        52\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.43       161\n",
      "   macro avg       0.45      0.26      0.20       161\n",
      "weighted avg       0.52      0.43      0.32       161\n",
      "\n",
      "===== LSTM Evaluation =====\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43478260869565216\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.03      0.06        34\n",
      "           1       0.43      1.00      0.60        69\n",
      "           2       0.00      0.00      0.00        52\n",
      "           3       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.43       161\n",
      "   macro avg       0.36      0.26      0.16       161\n",
      "weighted avg       0.40      0.43      0.27       161\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/med/jupyter_env/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install and import required packages\n",
    "!pip install nltk scikit-learn torch\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem.isri import ISRIStemmer\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# üîÅ Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# ‚úÖ Load your dataset\n",
    "df = pd.read_csv(\"data_semantically_scored.csv\")  # ‚Üê Replace with your filename\n",
    "\n",
    "# ‚úÖ Step 2: Preprocessing (tokenize, remove stopwords, stem, discretize)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stemmer = ISRIStemmer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('arabic'))\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = tokenizer.tokenize(str(text))\n",
    "    tokens = [t for t in tokens if t.isalpha() and t not in stop_words]\n",
    "    stemmed = [stemmer.stem(t) for t in tokens]\n",
    "    return ' '.join(stemmed)\n",
    "\n",
    "df['processed'] = df['title'].apply(preprocess)\n",
    "\n",
    "# Discretize score into 5 bins for classification\n",
    "# Discretize the score into 5 bins and handle NaNs safely\n",
    "df['score_bin'] = pd.cut(df['score'], bins=[0, 2, 4, 6, 8, 10], labels=[0, 1, 2, 3, 4])\n",
    "\n",
    "# Drop any rows with NaN bins\n",
    "df = df.dropna(subset=['score_bin'])\n",
    "\n",
    "# Convert to int after removing NaNs\n",
    "df['score_bin'] = df['score_bin'].astype(int)\n",
    "\n",
    "# ‚úÖ Step 3: Vectorization\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "X = vectorizer.fit_transform(df['processed']).toarray()\n",
    "y = df['score_bin'].values\n",
    "\n",
    "# ‚úÖ Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ‚úÖ Convert to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.long)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.long)\n",
    "\n",
    "train_data = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_data = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16)\n",
    "\n",
    "# ‚úÖ Step 3: Model Definition\n",
    "class TextClassifier(nn.Module):\n",
    "    def __init__(self, model_type='rnn', input_size=500, hidden_size=64, output_size=5):\n",
    "        super().__init__()\n",
    "        self.rnn_type = model_type\n",
    "        self.hidden = hidden_size\n",
    "\n",
    "        if model_type == 'gru':\n",
    "            self.rnn = nn.GRU(input_size, hidden_size, batch_first=True)\n",
    "        elif model_type == 'lstm':\n",
    "            self.rnn = nn.LSTM(input_size, hidden_size, batch_first=True)\n",
    "        elif model_type == 'birnn':\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True, bidirectional=True)\n",
    "        else:\n",
    "            self.rnn = nn.RNN(input_size, hidden_size, batch_first=True)\n",
    "\n",
    "        self.fc = nn.Linear(hidden_size * (2 if model_type == 'birnn' else 1), output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add sequence dimension\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out\n",
    "\n",
    "# ‚úÖ Training function\n",
    "def train_model(model_type):\n",
    "    model = TextClassifier(model_type)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for inputs, labels in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    return model\n",
    "\n",
    "# ‚úÖ Step 4: Evaluation\n",
    "def evaluate_model(model):\n",
    "    model.eval()\n",
    "    all_preds, all_true = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            all_preds.extend(preds.numpy())\n",
    "            all_true.extend(labels.numpy())\n",
    "    print(\"Accuracy:\", accuracy_score(all_true, all_preds))\n",
    "    print(classification_report(all_true, all_preds))\n",
    "\n",
    "# ‚úÖ Train & Evaluate All Models\n",
    "for model_type in ['rnn', 'birnn', 'gru', 'lstm']:\n",
    "    print(f\"===== {model_type.upper()} Evaluation =====\")\n",
    "    model = train_model(model_type)\n",
    "    evaluate_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451d3154-0e76-42f4-89fe-1b17198d3c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
