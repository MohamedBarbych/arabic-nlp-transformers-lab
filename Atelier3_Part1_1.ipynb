{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1dfb2684",
   "metadata": {},
   "source": [
    "\n",
    "# 🧠 Deep Learning – Atelier 3 – Arabic News Classification\n",
    "\n",
    "**Université Abdelmalek Essaadi – LSI**  \n",
    "**Instructor:** Pr. ELAACHAK LOTFI  \n",
    "\n",
    "This notebook covers:\n",
    "1. Scraping Arabic political news headlines using Selenium + BeautifulSoup.\n",
    "2. Assigning a relevance score (0 to 10) to each title using rule-based heuristics.\n",
    "3. Saving the dataset to a CSV file for further NLP model training.\n",
    "\n",
    "---\n",
    "\n",
    "## 📰 Step 1: Web Scraping with Selenium & BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca22218",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /home/med/jupyter_env/lib/python3.12/site-packages (4.31.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/med/jupyter_env/lib/python3.12/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in /home/med/jupyter_env/lib/python3.12/site-packages (2.2.3)\n",
      "Requirement already satisfied: nltk in /home/med/jupyter_env/lib/python3.12/site-packages (3.9.1)\n",
      "Requirement already satisfied: webdriver-manager in /home/med/jupyter_env/lib/python3.12/site-packages (4.0.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /home/med/jupyter_env/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.2.3)\n",
      "Requirement already satisfied: trio~=0.17 in /home/med/jupyter_env/lib/python3.12/site-packages (from selenium) (0.29.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /home/med/jupyter_env/lib/python3.12/site-packages (from selenium) (0.12.2)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/med/jupyter_env/lib/python3.12/site-packages (from selenium) (2024.8.30)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /home/med/jupyter_env/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /home/med/jupyter_env/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/med/jupyter_env/lib/python3.12/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/med/jupyter_env/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/med/jupyter_env/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /home/med/jupyter_env/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: click in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (8.1.8)\n",
      "Requirement already satisfied: joblib in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /home/med/jupyter_env/lib/python3.12/site-packages (from nltk) (4.67.1)\n",
      "Requirement already satisfied: requests in /home/med/jupyter_env/lib/python3.12/site-packages (from webdriver-manager) (2.32.3)\n",
      "Requirement already satisfied: python-dotenv in /home/med/jupyter_env/lib/python3.12/site-packages (from webdriver-manager) (1.1.0)\n",
      "Requirement already satisfied: packaging in /home/med/jupyter_env/lib/python3.12/site-packages (from webdriver-manager) (24.2)\n",
      "Requirement already satisfied: six>=1.5 in /home/med/jupyter_env/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /home/med/jupyter_env/lib/python3.12/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/med/jupyter_env/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Requirement already satisfied: outcome in /home/med/jupyter_env/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: wsproto>=0.14 in /home/med/jupyter_env/lib/python3.12/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in /home/med/jupyter_env/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/med/jupyter_env/lib/python3.12/site-packages (from requests->webdriver-manager) (3.4.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /home/med/jupyter_env/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>إسواتيني ترفض مناورات جنوب إفريقيا</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>من التدبير إلى التغيير.. المغرب يكثف التحركات ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هل تنجح الوساطة الأمريكية بين المغرب والجزائر ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ملف الصحراء: من نضج المبادرة المغربية إلى اختب...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تهديدات وزير الداخلية الفرنسي تعمق عزلة النظام...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score\n",
       "0                 إسواتيني ترفض مناورات جنوب إفريقيا      0\n",
       "1  من التدبير إلى التغيير.. المغرب يكثف التحركات ...      0\n",
       "2  هل تنجح الوساطة الأمريكية بين المغرب والجزائر ...      0\n",
       "3  ملف الصحراء: من نضج المبادرة المغربية إلى اختب...      0\n",
       "4  تهديدات وزير الداخلية الفرنسي تعمق عزلة النظام...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "!pip install selenium beautifulsoup4 pandas nltk webdriver-manager\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "url = \"https://www.hespress.com/politique\"\n",
    "\n",
    "# Set up headless Chrome\n",
    "options = Options()\n",
    "options.add_argument(\"--headless\")\n",
    "options.add_argument(\"--no-sandbox\")\n",
    "options.add_argument(\"--disable-dev-shm-usage\")\n",
    "\n",
    "driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)\n",
    "\n",
    "# Scroll and load content\n",
    "driver.get(url)\n",
    "end_time = time.time() + 60  # Scroll for 60 seconds\n",
    "\n",
    "while time.time() < end_time:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(2)\n",
    "\n",
    "# Parse page source\n",
    "soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "driver.quit()\n",
    "\n",
    "# Extract article titles\n",
    "titles = soup.find_all('a', class_='stretched-link')\n",
    "title_texts = [title.get('title') for title in titles if title.get('title')]\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(title_texts, columns=['title'])\n",
    "df['score'] = 0\n",
    "df.to_csv(\"data_scraped.csv\", index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13cfaff5",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 🧮 Step 2: Assigning Relevance Scores\n",
    "\n",
    "Using basic keyword matching to classify news articles as internal (score closer to 0) or external (score closer to 10).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "422c03ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/med/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>إسواتيني ترفض مناورات جنوب إفريقيا</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>من التدبير إلى التغيير.. المغرب يكثف التحركات ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>هل تنجح الوساطة الأمريكية بين المغرب والجزائر ...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ملف الصحراء: من نضج المبادرة المغربية إلى اختب...</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>تهديدات وزير الداخلية الفرنسي تعمق عزلة النظام...</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score\n",
       "0                 إسواتيني ترفض مناورات جنوب إفريقيا    2.5\n",
       "1  من التدبير إلى التغيير.. المغرب يكثف التحركات ...    3.0\n",
       "2  هل تنجح الوساطة الأمريكية بين المغرب والجزائر ...    3.0\n",
       "3  ملف الصحراء: من نضج المبادرة المغربية إلى اختب...    7.5\n",
       "4  تهديدات وزير الداخلية الفرنسي تعمق عزلة النظام...    3.5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "tokenizer = ToktokTokenizer()\n",
    "stop_words = set(nltk.corpus.stopwords.words('arabic'))\n",
    "\n",
    "external_keywords = ['إسرائيل', 'الأمم', 'الخارجية', 'الأمم المتحدة', 'فرنسا', 'أمريكا', 'البيت الأبيض', 'الأوروبي', 'الدولي']\n",
    "internal_keywords = ['المغرب', 'الرباط', 'الحكومة', 'مجلس', 'وزير', 'المغربية', 'جهة', 'الملك', 'الداخلية']\n",
    "\n",
    "df = pd.read_csv('data_scraped.csv')\n",
    "\n",
    "def compute_score(title):\n",
    "    words = tokenizer.tokenize(str(title))\n",
    "    keywords = [word for word in words if word not in stop_words and word.isalpha()]\n",
    "    \n",
    "    # Initial score\n",
    "    score = 0.0\n",
    "\n",
    "    # Keyword frequency\n",
    "    ext_hits = sum(1 for w in external_keywords if w in title)\n",
    "    int_hits = sum(1 for w in internal_keywords if w in title)\n",
    "    \n",
    "    score += ext_hits * 2\n",
    "    score -= int_hits * 1\n",
    "\n",
    "    # Add richness score\n",
    "    score += 0.5 * len(keywords)\n",
    "\n",
    "    # Bonus for long titles\n",
    "    if len(keywords) > 8:\n",
    "        score += 1\n",
    "\n",
    "    # Normalize to [0, 10]\n",
    "    score = min(10, max(0, round(score, 1)))\n",
    "    \n",
    "    return ' '.join(keywords), score\n",
    "\n",
    "df[['keywords', 'score']] = df['title'].apply(lambda x: pd.Series(compute_score(x)))\n",
    "df.to_csv(\"data_semantically_scored.csv\", index=False)\n",
    "df[['title', 'score']].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0092adb2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## ✅ Summary\n",
    "\n",
    "- We collected Arabic news titles from Hespress (Politics section).\n",
    "- We applied basic NLP techniques to assign a relevance score between 0–10.\n",
    "- Saved the processed data to `titles-scored.csv`.\n",
    "\n",
    "You can now proceed to:\n",
    "- Preprocessing pipeline (tokenization, lemmatization, etc.)\n",
    "- Model training: RNN, Bi-RNN, GRU, LSTM\n",
    "- Part 2: Fine-tuning GPT-2 for Arabic text generation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
